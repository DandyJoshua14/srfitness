{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 215, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/src/ai/genkit.ts"],"sourcesContent":["import {genkit} from 'genkit';\nimport {googleAI} from '@genkit-ai/googleai';\n\nexport const ai = genkit({\n  plugins: [googleAI()],\n  model: 'googleai/gemini-2.0-flash',\n});\n"],"names":[],"mappings":";;;AAAA;AAAA;AACA;AAAA;;;AAEO,MAAM,KAAK,CAAA,GAAA,uIAAA,CAAA,SAAM,AAAD,EAAE;IACvB,SAAS;QAAC,CAAA,GAAA,2KAAA,CAAA,WAAQ,AAAD;KAAI;IACrB,OAAO;AACT","debugId":null}},
    {"offset": {"line": 236, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/src/ai/flows/generate-voice-response-flow.ts"],"sourcesContent":["\n'use server';\n/**\n * @fileOverview A voice agent flow that responds to user queries and can navigate the site.\n *\n * - generateVoiceResponse - A function that handles the voice agent's response generation.\n * - VoiceAgentInput - The input type for the voice agent.\n * - VoiceAgentOutput - The return type for the voice agent, now including an optional navigation path.\n */\n\nimport { ai } from '@/ai/genkit';\nimport { z } from 'genkit';\n\nconst VoiceAgentInputSchema = z.object({\n  query: z.string().describe(\"The user's spoken query, transcribed to text.\"),\n});\nexport type VoiceAgentInput = z.infer<typeof VoiceAgentInputSchema>;\n\nconst VoiceAgentOutputSchema = z.object({\n  response: z.string().describe(\"The AI's text response to be spoken back to the user.\"),\n  navigationPath: z.string().nullable().optional().describe(\"An optional path to navigate to on the website (e.g., '/awards', '/meal-planner'). Should be null or omitted if no navigation is required.\"),\n});\nexport type VoiceAgentOutput = z.infer<typeof VoiceAgentOutputSchema>;\n\n// Define valid navigation paths\nconst validPaths = [\n    '/', '/personal-training', '/burn-off-bootcamp', '/awards', \n    '/lifestyle-magazine', '/public-speaking', '/equipment-services', '/#contact',\n    '/meal-planner', '/Smart Scan', '/global-connect', '/community', '/profile', \n    '/privacy-policy', '/terms-of-service', '/corporate-wellness', '/marketplace'\n] as const;\n\n// Define the navigation tool\nconst navigateToPage = ai.defineTool(\n    {\n      name: 'navigateToPage',\n      description: 'Use this tool to navigate the user to a specific page on the SR Fitness website when they ask to go somewhere. Use it for requests like \"go to\", \"take me to\", \"open\", \"show me\", etc.',\n      inputSchema: z.object({\n        path: z.enum(validPaths).describe(\"The page path to navigate to.\"),\n        pageName: z.string().describe(\"The friendly name of the page for confirmation message, e.g., 'the awards page', 'your profile'.\")\n      }),\n      outputSchema: z.string(),\n    },\n    async ({ path }) => `Navigating to ${path}`\n);\n\n\nexport async function generateVoiceResponse(input: VoiceAgentInput): Promise<VoiceAgentOutput> {\n  return generateVoiceResponseFlow(input);\n}\n\nconst prompt = ai.definePrompt({\n  name: 'voiceAgentPrompt',\n  input: { schema: VoiceAgentInputSchema },\n  output: { schema: VoiceAgentOutputSchema },\n  tools: [navigateToPage],\n  prompt: `You are Ninna, a friendly and helpful voice assistant for the SR Fitness application.\nYour role is to answer user questions about fitness, nutrition, our services, or general inquiries.\nIf the user asks to navigate to a page (e.g., \"go to\", \"open\", \"show me\"), you MUST use the navigateToPage tool.\nIf you are not navigating, provide a helpful text response and ensure the navigationPath is null.\nBe conversational, encouraging, and keep your answers concise and clear, as they will be spoken aloud.\nIf you don't know an answer, say so politely.\n\nUser query: {{{query}}}\n  `,\n});\n\nconst generateVoiceResponseFlow = ai.defineFlow(\n  {\n    name: 'generateVoiceResponseFlow',\n    inputSchema: VoiceAgentInputSchema,\n    outputSchema: VoiceAgentOutputSchema,\n  },\n  async (input) => {\n    const response = await prompt(input);\n\n    // 1. Check for tool calls first\n    const toolCalls = response.toolCalls;\n    if (toolCalls && toolCalls.length > 0) {\n        const navigateCall = toolCalls.find(call => call.tool === 'navigateToPage');\n        if (navigateCall) {\n            const { path, pageName } = navigateCall.input as { path: string; pageName: string };\n            return {\n                response: `Of course, taking you to ${pageName} now.`,\n                navigationPath: path,\n            };\n        }\n    }\n    \n    // 2. If no tool call, check for structured output\n    const output = response.output;\n    if (output) {\n      return {\n          response: output.response,\n          navigationPath: output.navigationPath || null\n      };\n    }\n\n    // 3. If no structured output, check for a simple text response as a fallback\n    const text = response.text;\n    if (text) {\n        return {\n            response: text,\n            navigationPath: null\n        };\n    }\n\n    // 4. Fallback if we have neither tool calls, structured output, nor text\n    return { response: \"I'm sorry, I had a problem thinking of a response. Please try again.\", navigationPath: null };\n  }\n);\n"],"names":[],"mappings":";;;;;AAEA;;;;;;CAMC,GAED;AACA;AAAA;;;;;;AAEA,MAAM,wBAAwB,uIAAA,CAAA,IAAC,CAAC,MAAM,CAAC;IACrC,OAAO,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;AAC7B;AAGA,MAAM,yBAAyB,uIAAA,CAAA,IAAC,CAAC,MAAM,CAAC;IACtC,UAAU,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;IAC9B,gBAAgB,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,GAAG,QAAQ,GAAG,QAAQ,CAAC;AAC5D;AAGA,gCAAgC;AAChC,MAAM,aAAa;IACf;IAAK;IAAsB;IAAsB;IACjD;IAAuB;IAAoB;IAAuB;IAClE;IAAiB;IAAe;IAAmB;IAAc;IACjE;IAAmB;IAAqB;IAAuB;CAClE;AAED,6BAA6B;AAC7B,MAAM,iBAAiB,mHAAA,CAAA,KAAE,CAAC,UAAU,CAChC;IACE,MAAM;IACN,aAAa;IACb,aAAa,uIAAA,CAAA,IAAC,CAAC,MAAM,CAAC;QACpB,MAAM,uIAAA,CAAA,IAAC,CAAC,IAAI,CAAC,YAAY,QAAQ,CAAC;QAClC,UAAU,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;IAChC;IACA,cAAc,uIAAA,CAAA,IAAC,CAAC,MAAM;AACxB,GACA,OAAO,EAAE,IAAI,EAAE,GAAK,CAAC,cAAc,EAAE,MAAM;AAIxC,eAAe,sBAAsB,KAAsB;IAChE,OAAO,0BAA0B;AACnC;AAEA,MAAM,SAAS,mHAAA,CAAA,KAAE,CAAC,YAAY,CAAC;IAC7B,MAAM;IACN,OAAO;QAAE,QAAQ;IAAsB;IACvC,QAAQ;QAAE,QAAQ;IAAuB;IACzC,OAAO;QAAC;KAAe;IACvB,QAAQ,CAAC;;;;;;;;EAQT,CAAC;AACH;AAEA,MAAM,4BAA4B,mHAAA,CAAA,KAAE,CAAC,UAAU,CAC7C;IACE,MAAM;IACN,aAAa;IACb,cAAc;AAChB,GACA,OAAO;IACL,MAAM,WAAW,MAAM,OAAO;IAE9B,gCAAgC;IAChC,MAAM,YAAY,SAAS,SAAS;IACpC,IAAI,aAAa,UAAU,MAAM,GAAG,GAAG;QACnC,MAAM,eAAe,UAAU,IAAI,CAAC,CAAA,OAAQ,KAAK,IAAI,KAAK;QAC1D,IAAI,cAAc;YACd,MAAM,EAAE,IAAI,EAAE,QAAQ,EAAE,GAAG,aAAa,KAAK;YAC7C,OAAO;gBACH,UAAU,CAAC,yBAAyB,EAAE,SAAS,KAAK,CAAC;gBACrD,gBAAgB;YACpB;QACJ;IACJ;IAEA,kDAAkD;IAClD,MAAM,SAAS,SAAS,MAAM;IAC9B,IAAI,QAAQ;QACV,OAAO;YACH,UAAU,OAAO,QAAQ;YACzB,gBAAgB,OAAO,cAAc,IAAI;QAC7C;IACF;IAEA,6EAA6E;IAC7E,MAAM,OAAO,SAAS,IAAI;IAC1B,IAAI,MAAM;QACN,OAAO;YACH,UAAU;YACV,gBAAgB;QACpB;IACJ;IAEA,yEAAyE;IACzE,OAAO;QAAE,UAAU;QAAwE,gBAAgB;IAAK;AAClH;;;IA9DoB;;AAAA,+OAAA","debugId":null}},
    {"offset": {"line": 391, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/src/ai/flows/generate-speech-audio-flow.ts"],"sourcesContent":["\n'use server';\n/**\n * @fileOverview Converts text to speech audio.\n *\n * - generateSpeechAudio - Converts text into a WAV audio data URI.\n */\n\nimport { ai } from '@/ai/genkit';\nimport { z } from 'genkit';\nimport wav from 'wav';\nimport { googleAI } from '@genkit-ai/googleai';\n\n// This is the exported function React components will call.\nexport async function generateSpeechAudio(text: string): Promise<string> {\n  return generateSpeechAudioFlow(text);\n}\n\nconst generateSpeechAudioFlow = ai.defineFlow(\n  {\n    name: 'generateSpeechAudioFlow',\n    inputSchema: z.string(),\n    outputSchema: z.string(), // data URI\n  },\n  async (text) => {\n    if (!text.trim()) {\n      return '';\n    }\n\n    const { media } = await ai.generate({\n      model: googleAI.model('gemini-2.5-flash-preview-tts'),\n      config: {\n        responseModalities: ['AUDIO'],\n        speechConfig: {\n          voiceConfig: {\n            prebuiltVoiceConfig: { voiceName: 'Umbriel' }, // Updated to a valid female-sounding voice\n          },\n        },\n      },\n      prompt: text,\n    });\n\n    if (!media) {\n      throw new Error('No audio media was returned from the TTS model.');\n    }\n\n    // The media URL is a data URI with raw PCM data\n    // Format: 'data:audio/L16;rate=24000;channels=1;base64,....'\n    const audioBuffer = Buffer.from(\n      media.url.substring(media.url.indexOf(',') + 1),\n      'base64'\n    );\n    \n    const wavDataUri = await toWavDataUri(audioBuffer);\n    return wavDataUri;\n  }\n);\n\n// Helper function to convert raw PCM audio buffer to a WAV data URI\nasync function toWavDataUri(\n  pcmData: Buffer,\n  channels = 1,\n  rate = 24000,\n  sampleWidth = 2\n): Promise<string> {\n  return new Promise((resolve, reject) => {\n    const writer = new wav.Writer({\n      channels,\n      sampleRate: rate,\n      bitDepth: sampleWidth * 8,\n    });\n\n    const buffers: Buffer[] = [];\n    writer.on('data', (chunk) => {\n      buffers.push(chunk);\n    });\n    writer.on('end', () => {\n      const wavBuffer = Buffer.concat(buffers);\n      resolve(`data:audio/wav;base64,${wavBuffer.toString('base64')}`);\n    });\n    writer.on('error', reject);\n\n    writer.write(pcmData);\n    writer.end();\n  });\n}\n"],"names":[],"mappings":";;;;;AAEA;;;;CAIC,GAED;AACA;AAAA;AACA;AACA;AAAA;;;;;;;;AAGO,eAAe,oBAAoB,IAAY;IACpD,OAAO,wBAAwB;AACjC;AAEA,MAAM,0BAA0B,mHAAA,CAAA,KAAE,CAAC,UAAU,CAC3C;IACE,MAAM;IACN,aAAa,uIAAA,CAAA,IAAC,CAAC,MAAM;IACrB,cAAc,uIAAA,CAAA,IAAC,CAAC,MAAM;AACxB,GACA,OAAO;IACL,IAAI,CAAC,KAAK,IAAI,IAAI;QAChB,OAAO;IACT;IAEA,MAAM,EAAE,KAAK,EAAE,GAAG,MAAM,mHAAA,CAAA,KAAE,CAAC,QAAQ,CAAC;QAClC,OAAO,2KAAA,CAAA,WAAQ,CAAC,KAAK,CAAC;QACtB,QAAQ;YACN,oBAAoB;gBAAC;aAAQ;YAC7B,cAAc;gBACZ,aAAa;oBACX,qBAAqB;wBAAE,WAAW;oBAAU;gBAC9C;YACF;QACF;QACA,QAAQ;IACV;IAEA,IAAI,CAAC,OAAO;QACV,MAAM,IAAI,MAAM;IAClB;IAEA,gDAAgD;IAChD,6DAA6D;IAC7D,MAAM,cAAc,OAAO,IAAI,CAC7B,MAAM,GAAG,CAAC,SAAS,CAAC,MAAM,GAAG,CAAC,OAAO,CAAC,OAAO,IAC7C;IAGF,MAAM,aAAa,MAAM,aAAa;IACtC,OAAO;AACT;AAGF,oEAAoE;AACpE,eAAe,aACb,OAAe,EACf,WAAW,CAAC,EACZ,OAAO,KAAK,EACZ,cAAc,CAAC;IAEf,OAAO,IAAI,QAAQ,CAAC,SAAS;QAC3B,MAAM,SAAS,IAAI,4HAAA,CAAA,UAAG,CAAC,MAAM,CAAC;YAC5B;YACA,YAAY;YACZ,UAAU,cAAc;QAC1B;QAEA,MAAM,UAAoB,EAAE;QAC5B,OAAO,EAAE,CAAC,QAAQ,CAAC;YACjB,QAAQ,IAAI,CAAC;QACf;QACA,OAAO,EAAE,CAAC,OAAO;YACf,MAAM,YAAY,OAAO,MAAM,CAAC;YAChC,QAAQ,CAAC,sBAAsB,EAAE,UAAU,QAAQ,CAAC,WAAW;QACjE;QACA,OAAO,EAAE,CAAC,SAAS;QAEnB,OAAO,KAAK,CAAC;QACb,OAAO,GAAG;IACZ;AACF;;;IAvEsB;;AAAA,+OAAA","debugId":null}},
    {"offset": {"line": 481, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/.next-internal/server/app/public-speaking/page/actions.js%20%28server%20actions%20loader%29"],"sourcesContent":["export {generateVoiceResponse as '40d4ef3f17cac6671f3ce0fae5b2a708376fff0fbf'} from 'ACTIONS_MODULE0'\nexport {generateSpeechAudio as '40f3233a4d6b07c47e7e48dcd2d0a4954be17da116'} from 'ACTIONS_MODULE1'\n"],"names":[],"mappings":";AAAA;AACA","debugId":null}},
    {"offset": {"line": 539, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/src/app/public-speaking/page.tsx/proxy.mjs"],"sourcesContent":["import { registerClientReference } from \"react-server-dom-turbopack/server.edge\";\nexport default registerClientReference(\n    function() { throw new Error(\"Attempted to call the default export of [project]/src/app/public-speaking/page.tsx <module evaluation> from the server, but it's on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.\"); },\n    \"[project]/src/app/public-speaking/page.tsx <module evaluation>\",\n    \"default\",\n);\n"],"names":[],"mappings":";;;AAAA;;uCACe,CAAA,GAAA,qPAAA,CAAA,0BAAuB,AAAD,EACjC;IAAa,MAAM,IAAI,MAAM;AAAoS,GACjU,kEACA","debugId":null}},
    {"offset": {"line": 553, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/src/app/public-speaking/page.tsx/proxy.mjs"],"sourcesContent":["import { registerClientReference } from \"react-server-dom-turbopack/server.edge\";\nexport default registerClientReference(\n    function() { throw new Error(\"Attempted to call the default export of [project]/src/app/public-speaking/page.tsx from the server, but it's on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.\"); },\n    \"[project]/src/app/public-speaking/page.tsx\",\n    \"default\",\n);\n"],"names":[],"mappings":";;;AAAA;;uCACe,CAAA,GAAA,qPAAA,CAAA,0BAAuB,AAAD,EACjC;IAAa,MAAM,IAAI,MAAM;AAAgR,GAC7S,8CACA","debugId":null}},
    {"offset": {"line": 567, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"","debugId":null}}]
}