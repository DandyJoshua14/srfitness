{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 215, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/src/ai/genkit.ts"],"sourcesContent":["import {genkit} from 'genkit';\nimport {googleAI} from '@genkit-ai/googleai';\n\nexport const ai = genkit({\n  plugins: [googleAI()],\n  model: 'googleai/gemini-2.0-flash',\n});\n"],"names":[],"mappings":";;;AAAA;AAAA;AACA;AAAA;;;AAEO,MAAM,KAAK,CAAA,GAAA,uIAAA,CAAA,SAAM,AAAD,EAAE;IACvB,SAAS;QAAC,CAAA,GAAA,2KAAA,CAAA,WAAQ,AAAD;KAAI;IACrB,OAAO;AACT","debugId":null}},
    {"offset": {"line": 236, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/src/ai/flows/generate-voice-response-flow.ts"],"sourcesContent":["\n'use server';\n/**\n * @fileOverview A voice agent flow that responds to user queries and can navigate the site.\n *\n * - generateVoiceResponse - A function that handles the voice agent's response generation.\n * - VoiceAgentInput - The input type for the voice agent.\n * - VoiceAgentOutput - The return type for the voice agent, now including an optional navigation path.\n */\n\nimport { ai } from '@/ai/genkit';\nimport { z } from 'genkit';\n\nconst VoiceAgentInputSchema = z.object({\n  query: z.string().describe(\"The user's spoken query, transcribed to text.\"),\n});\nexport type VoiceAgentInput = z.infer<typeof VoiceAgentInputSchema>;\n\nconst VoiceAgentOutputSchema = z.object({\n  response: z.string().describe(\"The AI's text response to be spoken back to the user.\"),\n  navigationPath: z.string().nullable().optional().describe(\"An optional path to navigate to on the website (e.g., '/awards', '/meal-planner'). Should be null or omitted if no navigation is required.\"),\n});\nexport type VoiceAgentOutput = z.infer<typeof VoiceAgentOutputSchema>;\n\n// Define valid navigation paths\nconst validPaths = [\n    '/', '/personal-training', '/burn-off-bootcamp', '/awards', \n    '/lifestyle-magazine', '/public-speaking', '/equipment-services', '/#contact',\n    '/meal-planner', '/Smart Scan', '/global-connect', '/community', '/profile', \n    '/privacy-policy', '/terms-of-service', '/corporate-wellness', '/marketplace'\n] as const;\n\n// Define the navigation tool\nconst navigateToPage = ai.defineTool(\n    {\n      name: 'navigateToPage',\n      description: 'Use this tool to navigate the user to a specific page on the SR Fitness website when they ask to go somewhere. Use it for requests like \"go to\", \"take me to\", \"open\", \"show me\", etc.',\n      inputSchema: z.object({\n        path: z.enum(validPaths).describe(\"The page path to navigate to.\"),\n        pageName: z.string().describe(\"The friendly name of the page for confirmation message, e.g., 'the awards page', 'your profile'.\")\n      }),\n      outputSchema: z.string(),\n    },\n    async ({ path }) => `Navigating to ${path}`\n);\n\n\nexport async function generateVoiceResponse(input: VoiceAgentInput): Promise<VoiceAgentOutput> {\n  return generateVoiceResponseFlow(input);\n}\n\nconst prompt = ai.definePrompt({\n  name: 'voiceAgentPrompt',\n  input: { schema: VoiceAgentInputSchema },\n  output: { schema: VoiceAgentOutputSchema },\n  tools: [navigateToPage],\n  prompt: `You are Ninna, a friendly and helpful voice assistant for the SR Fitness application.\nYour role is to answer user questions about fitness, nutrition, our services, or general inquiries.\nIf the user asks to navigate to a page (e.g., \"go to\", \"open\", \"show me\"), you MUST use the navigateToPage tool.\nIf you are not navigating, provide a helpful text response and ensure the navigationPath is null.\nBe conversational, encouraging, and keep your answers concise and clear, as they will be spoken aloud.\nIf you don't know an answer, say so politely.\n\nUser query: {{{query}}}\n  `,\n});\n\nconst generateVoiceResponseFlow = ai.defineFlow(\n  {\n    name: 'generateVoiceResponseFlow',\n    inputSchema: VoiceAgentInputSchema,\n    outputSchema: VoiceAgentOutputSchema,\n  },\n  async (input) => {\n    const response = await prompt(input);\n\n    // 1. Check for tool calls first\n    const toolCalls = response.toolCalls;\n    if (toolCalls && toolCalls.length > 0) {\n        const navigateCall = toolCalls.find(call => call.tool === 'navigateToPage');\n        if (navigateCall) {\n            const { path, pageName } = navigateCall.input as { path: string; pageName: string };\n            return {\n                response: `Of course, taking you to ${pageName} now.`,\n                navigationPath: path,\n            };\n        }\n    }\n    \n    // 2. If no tool call, check for structured output\n    const output = response.output;\n    if (output) {\n      return {\n          response: output.response,\n          navigationPath: output.navigationPath || null\n      };\n    }\n\n    // 3. If no structured output, check for a simple text response as a fallback\n    const text = response.text;\n    if (text) {\n        return {\n            response: text,\n            navigationPath: null\n        };\n    }\n\n    // 4. Fallback if we have neither tool calls, structured output, nor text\n    return { response: \"I'm sorry, I had a problem thinking of a response. Please try again.\", navigationPath: null };\n  }\n);\n"],"names":[],"mappings":";;;;;AAEA;;;;;;CAMC,GAED;AACA;AAAA;;;;;;AAEA,MAAM,wBAAwB,uIAAA,CAAA,IAAC,CAAC,MAAM,CAAC;IACrC,OAAO,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;AAC7B;AAGA,MAAM,yBAAyB,uIAAA,CAAA,IAAC,CAAC,MAAM,CAAC;IACtC,UAAU,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;IAC9B,gBAAgB,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,GAAG,QAAQ,GAAG,QAAQ,CAAC;AAC5D;AAGA,gCAAgC;AAChC,MAAM,aAAa;IACf;IAAK;IAAsB;IAAsB;IACjD;IAAuB;IAAoB;IAAuB;IAClE;IAAiB;IAAe;IAAmB;IAAc;IACjE;IAAmB;IAAqB;IAAuB;CAClE;AAED,6BAA6B;AAC7B,MAAM,iBAAiB,mHAAA,CAAA,KAAE,CAAC,UAAU,CAChC;IACE,MAAM;IACN,aAAa;IACb,aAAa,uIAAA,CAAA,IAAC,CAAC,MAAM,CAAC;QACpB,MAAM,uIAAA,CAAA,IAAC,CAAC,IAAI,CAAC,YAAY,QAAQ,CAAC;QAClC,UAAU,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;IAChC;IACA,cAAc,uIAAA,CAAA,IAAC,CAAC,MAAM;AACxB,GACA,OAAO,EAAE,IAAI,EAAE,GAAK,CAAC,cAAc,EAAE,MAAM;AAIxC,eAAe,sBAAsB,KAAsB;IAChE,OAAO,0BAA0B;AACnC;AAEA,MAAM,SAAS,mHAAA,CAAA,KAAE,CAAC,YAAY,CAAC;IAC7B,MAAM;IACN,OAAO;QAAE,QAAQ;IAAsB;IACvC,QAAQ;QAAE,QAAQ;IAAuB;IACzC,OAAO;QAAC;KAAe;IACvB,QAAQ,CAAC;;;;;;;;EAQT,CAAC;AACH;AAEA,MAAM,4BAA4B,mHAAA,CAAA,KAAE,CAAC,UAAU,CAC7C;IACE,MAAM;IACN,aAAa;IACb,cAAc;AAChB,GACA,OAAO;IACL,MAAM,WAAW,MAAM,OAAO;IAE9B,gCAAgC;IAChC,MAAM,YAAY,SAAS,SAAS;IACpC,IAAI,aAAa,UAAU,MAAM,GAAG,GAAG;QACnC,MAAM,eAAe,UAAU,IAAI,CAAC,CAAA,OAAQ,KAAK,IAAI,KAAK;QAC1D,IAAI,cAAc;YACd,MAAM,EAAE,IAAI,EAAE,QAAQ,EAAE,GAAG,aAAa,KAAK;YAC7C,OAAO;gBACH,UAAU,CAAC,yBAAyB,EAAE,SAAS,KAAK,CAAC;gBACrD,gBAAgB;YACpB;QACJ;IACJ;IAEA,kDAAkD;IAClD,MAAM,SAAS,SAAS,MAAM;IAC9B,IAAI,QAAQ;QACV,OAAO;YACH,UAAU,OAAO,QAAQ;YACzB,gBAAgB,OAAO,cAAc,IAAI;QAC7C;IACF;IAEA,6EAA6E;IAC7E,MAAM,OAAO,SAAS,IAAI;IAC1B,IAAI,MAAM;QACN,OAAO;YACH,UAAU;YACV,gBAAgB;QACpB;IACJ;IAEA,yEAAyE;IACzE,OAAO;QAAE,UAAU;QAAwE,gBAAgB;IAAK;AAClH;;;IA9DoB;;AAAA,+OAAA","debugId":null}},
    {"offset": {"line": 391, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/src/ai/flows/generate-speech-audio-flow.ts"],"sourcesContent":["\n'use server';\n/**\n * @fileOverview Converts text to speech audio.\n *\n * - generateSpeechAudio - Converts text into a WAV audio data URI.\n */\n\nimport { ai } from '@/ai/genkit';\nimport { z } from 'genkit';\nimport wav from 'wav';\nimport { googleAI } from '@genkit-ai/googleai';\n\n// This is the exported function React components will call.\nexport async function generateSpeechAudio(text: string): Promise<string> {\n  return generateSpeechAudioFlow(text);\n}\n\nconst generateSpeechAudioFlow = ai.defineFlow(\n  {\n    name: 'generateSpeechAudioFlow',\n    inputSchema: z.string(),\n    outputSchema: z.string(), // data URI\n  },\n  async (text) => {\n    if (!text.trim()) {\n      return '';\n    }\n\n    const { media } = await ai.generate({\n      model: googleAI.model('gemini-2.5-flash-preview-tts'),\n      config: {\n        responseModalities: ['AUDIO'],\n        speechConfig: {\n          voiceConfig: {\n            prebuiltVoiceConfig: { voiceName: 'Umbriel' }, // Updated to a valid female-sounding voice\n          },\n        },\n      },\n      prompt: text,\n    });\n\n    if (!media) {\n      throw new Error('No audio media was returned from the TTS model.');\n    }\n\n    // The media URL is a data URI with raw PCM data\n    // Format: 'data:audio/L16;rate=24000;channels=1;base64,....'\n    const audioBuffer = Buffer.from(\n      media.url.substring(media.url.indexOf(',') + 1),\n      'base64'\n    );\n    \n    const wavDataUri = await toWavDataUri(audioBuffer);\n    return wavDataUri;\n  }\n);\n\n// Helper function to convert raw PCM audio buffer to a WAV data URI\nasync function toWavDataUri(\n  pcmData: Buffer,\n  channels = 1,\n  rate = 24000,\n  sampleWidth = 2\n): Promise<string> {\n  return new Promise((resolve, reject) => {\n    const writer = new wav.Writer({\n      channels,\n      sampleRate: rate,\n      bitDepth: sampleWidth * 8,\n    });\n\n    const buffers: Buffer[] = [];\n    writer.on('data', (chunk) => {\n      buffers.push(chunk);\n    });\n    writer.on('end', () => {\n      const wavBuffer = Buffer.concat(buffers);\n      resolve(`data:audio/wav;base64,${wavBuffer.toString('base64')}`);\n    });\n    writer.on('error', reject);\n\n    writer.write(pcmData);\n    writer.end();\n  });\n}\n"],"names":[],"mappings":";;;;;AAEA;;;;CAIC,GAED;AACA;AAAA;AACA;AACA;AAAA;;;;;;;;AAGO,eAAe,oBAAoB,IAAY;IACpD,OAAO,wBAAwB;AACjC;AAEA,MAAM,0BAA0B,mHAAA,CAAA,KAAE,CAAC,UAAU,CAC3C;IACE,MAAM;IACN,aAAa,uIAAA,CAAA,IAAC,CAAC,MAAM;IACrB,cAAc,uIAAA,CAAA,IAAC,CAAC,MAAM;AACxB,GACA,OAAO;IACL,IAAI,CAAC,KAAK,IAAI,IAAI;QAChB,OAAO;IACT;IAEA,MAAM,EAAE,KAAK,EAAE,GAAG,MAAM,mHAAA,CAAA,KAAE,CAAC,QAAQ,CAAC;QAClC,OAAO,2KAAA,CAAA,WAAQ,CAAC,KAAK,CAAC;QACtB,QAAQ;YACN,oBAAoB;gBAAC;aAAQ;YAC7B,cAAc;gBACZ,aAAa;oBACX,qBAAqB;wBAAE,WAAW;oBAAU;gBAC9C;YACF;QACF;QACA,QAAQ;IACV;IAEA,IAAI,CAAC,OAAO;QACV,MAAM,IAAI,MAAM;IAClB;IAEA,gDAAgD;IAChD,6DAA6D;IAC7D,MAAM,cAAc,OAAO,IAAI,CAC7B,MAAM,GAAG,CAAC,SAAS,CAAC,MAAM,GAAG,CAAC,OAAO,CAAC,OAAO,IAC7C;IAGF,MAAM,aAAa,MAAM,aAAa;IACtC,OAAO;AACT;AAGF,oEAAoE;AACpE,eAAe,aACb,OAAe,EACf,WAAW,CAAC,EACZ,OAAO,KAAK,EACZ,cAAc,CAAC;IAEf,OAAO,IAAI,QAAQ,CAAC,SAAS;QAC3B,MAAM,SAAS,IAAI,4HAAA,CAAA,UAAG,CAAC,MAAM,CAAC;YAC5B;YACA,YAAY;YACZ,UAAU,cAAc;QAC1B;QAEA,MAAM,UAAoB,EAAE;QAC5B,OAAO,EAAE,CAAC,QAAQ,CAAC;YACjB,QAAQ,IAAI,CAAC;QACf;QACA,OAAO,EAAE,CAAC,OAAO;YACf,MAAM,YAAY,OAAO,MAAM,CAAC;YAChC,QAAQ,CAAC,sBAAsB,EAAE,UAAU,QAAQ,CAAC,WAAW;QACjE;QACA,OAAO,EAAE,CAAC,SAAS;QAEnB,OAAO,KAAK,CAAC;QACb,OAAO,GAAG;IACZ;AACF;;;IAvEsB;;AAAA,+OAAA","debugId":null}},
    {"offset": {"line": 481, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/src/ai/flows/generate-content-flow.ts"],"sourcesContent":["\n'use server';\n/**\n * @fileOverview A content generation AI flow for the Admin Content Studio.\n *\n * - generateStudioContent - Generates content based on various inputs.\n * - GenerateStudioContentInput - The input type for the content generation.\n * - GenerateStudioContentOutput - The return type for the content generation.\n */\n\nimport {ai} from '@/ai/genkit';\nimport {z} from 'genkit';\n\nconst GenerateStudioContentInputSchema = z.object({\n  inputText: z.string().optional().describe('The base text, notes, or script to use for generation.'),\n  contentType: z.string().describe(\"The type of content to generate (e.g., 'Blog Post', 'Social Media Post', 'Podcast Script').\"),\n  tone: z.string().optional().describe('The desired tone of the content.'),\n  length: z.string().optional().describe('The desired length of the content.'),\n  audience: z.string().optional().describe('The target audience for the content.'),\n  keywords: z.string().optional().describe('Comma-separated keywords to include.'),\n});\nexport type GenerateStudioContentInput = z.infer<typeof GenerateStudioContentInputSchema>;\n\nconst GenerateStudioContentOutputSchema = z.object({\n  title: z.string().describe('The generated title for the content.'),\n  content: z.string().describe('The main body of the generated content.'),\n  socialMediaPost: z.string().optional().describe('A suggested social media post to promote the content.'),\n});\nexport type GenerateStudioContentOutput = z.infer<typeof GenerateStudioContentOutputSchema>;\n\nexport async function generateStudioContent(input: GenerateStudioContentInput): Promise<GenerateStudioContentOutput> {\n  const prompt = ai.definePrompt({\n    name: 'generateStudioContentPrompt',\n    input: {schema: GenerateStudioContentInputSchema},\n    output: {schema: GenerateStudioContentOutputSchema},\n    prompt: `You are an expert content creator and marketing assistant for SR Fitness.\nYour task is to generate a compelling \"{{contentType}}\" based on the user's input and configuration.\n\n**Content Generation Request:**\n- **Content Type:** {{contentType}}\n{{#if tone}}- **Tone:** {{tone}}{{/if}}\n{{#if length}}- **Length:** {{length}}{{/if}}\n{{#if audience}}- **Target Audience:** {{audience}}{{/if}}\n{{#if keywords}}- **Keywords to include:** {{keywords}}{{/if}}\n\n{{#if inputText}}\n**Base Input Text/Notes:**\n---\n{{{inputText}}}\n---\n{{/if}}\n\n**Instructions:**\n1.  **Analyze the request:** Understand the type of content, tone, length, audience, and keywords.\n2.  **Use the Base Input:** If inputText is provided, use it as the primary source material. Expand on it, rewrite it, or summarize it as appropriate for the requested content type. If it's empty, generate content from scratch based on the other parameters.\n3.  **Generate the Title:** Create a catchy and relevant title for the content.\n4.  **Generate the Content:** Write the main body of the content. For a blog post, this should be well-structured with paragraphs. For a podcast script, it should be conversational. For a social media post, it should be concise and engaging.\n5.  **Generate a Social Media Post:** Create a short, engaging social media post (e.g., for Instagram or Facebook) to promote this new piece of content. Include relevant hashtags based on the keywords and topic.\n6.  **Adhere to all parameters:** Ensure the final output matches the requested tone, length, audience, and includes the specified keywords naturally.\n`,\n  });\n\n  const generateStudioContentFlow = ai.defineFlow(\n    {\n      name: 'generateStudioContentFlow',\n      inputSchema: GenerateStudioContentInputSchema,\n      outputSchema: GenerateStudioContentOutputSchema,\n    },\n    async (input) => {\n      const {output} = await prompt(input);\n      if (!output) {\n        throw new Error('The AI model failed to generate content. Please try again.');\n      }\n      return output;\n    }\n  );\n\n  return generateStudioContentFlow(input);\n}\n"],"names":[],"mappings":";;;;;AAEA;;;;;;CAMC,GAED;AACA;AAAA;;;;;;AAEA,MAAM,mCAAmC,uIAAA,CAAA,IAAC,CAAC,MAAM,CAAC;IAChD,WAAW,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,GAAG,QAAQ,CAAC;IAC1C,aAAa,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;IACjC,MAAM,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,GAAG,QAAQ,CAAC;IACrC,QAAQ,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,GAAG,QAAQ,CAAC;IACvC,UAAU,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,GAAG,QAAQ,CAAC;IACzC,UAAU,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,GAAG,QAAQ,CAAC;AAC3C;AAGA,MAAM,oCAAoC,uIAAA,CAAA,IAAC,CAAC,MAAM,CAAC;IACjD,OAAO,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;IAC3B,SAAS,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;IAC7B,iBAAiB,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,GAAG,QAAQ,CAAC;AAClD;AAGO,eAAe,sBAAsB,KAAiC;IAC3E,MAAM,SAAS,mHAAA,CAAA,KAAE,CAAC,YAAY,CAAC;QAC7B,MAAM;QACN,OAAO;YAAC,QAAQ;QAAgC;QAChD,QAAQ;YAAC,QAAQ;QAAiC;QAClD,QAAQ,CAAC;;;;;;;;;;;;;;;;;;;;;;;;AAwBb,CAAC;IACC;IAEA,MAAM,4BAA4B,mHAAA,CAAA,KAAE,CAAC,UAAU,CAC7C;QACE,MAAM;QACN,aAAa;QACb,cAAc;IAChB,GACA,OAAO;QACL,MAAM,EAAC,MAAM,EAAC,GAAG,MAAM,OAAO;QAC9B,IAAI,CAAC,QAAQ;YACX,MAAM,IAAI,MAAM;QAClB;QACA,OAAO;IACT;IAGF,OAAO,0BAA0B;AACnC;;;IAhDsB;;AAAA,+OAAA","debugId":null}},
    {"offset": {"line": 572, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/.next-internal/server/app/admin/content-studio/page/actions.js%20%28server%20actions%20loader%29"],"sourcesContent":["export {generateVoiceResponse as '40d4ef3f17cac6671f3ce0fae5b2a708376fff0fbf'} from 'ACTIONS_MODULE0'\nexport {generateSpeechAudio as '40f3233a4d6b07c47e7e48dcd2d0a4954be17da116'} from 'ACTIONS_MODULE1'\nexport {generateStudioContent as '40a51c681a9badef9745d2a41a3406e73fd6e78e10'} from 'ACTIONS_MODULE2'\n"],"names":[],"mappings":";AAAA;AACA;AACA","debugId":null}},
    {"offset": {"line": 636, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/src/app/admin/content-studio/page.tsx/proxy.mjs"],"sourcesContent":["import { registerClientReference } from \"react-server-dom-turbopack/server.edge\";\nexport default registerClientReference(\n    function() { throw new Error(\"Attempted to call the default export of [project]/src/app/admin/content-studio/page.tsx <module evaluation> from the server, but it's on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.\"); },\n    \"[project]/src/app/admin/content-studio/page.tsx <module evaluation>\",\n    \"default\",\n);\n"],"names":[],"mappings":";;;AAAA;;uCACe,CAAA,GAAA,qPAAA,CAAA,0BAAuB,AAAD,EACjC;IAAa,MAAM,IAAI,MAAM;AAAyS,GACtU,uEACA","debugId":null}},
    {"offset": {"line": 650, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/src/app/admin/content-studio/page.tsx/proxy.mjs"],"sourcesContent":["import { registerClientReference } from \"react-server-dom-turbopack/server.edge\";\nexport default registerClientReference(\n    function() { throw new Error(\"Attempted to call the default export of [project]/src/app/admin/content-studio/page.tsx from the server, but it's on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.\"); },\n    \"[project]/src/app/admin/content-studio/page.tsx\",\n    \"default\",\n);\n"],"names":[],"mappings":";;;AAAA;;uCACe,CAAA,GAAA,qPAAA,CAAA,0BAAuB,AAAD,EACjC;IAAa,MAAM,IAAI,MAAM;AAAqR,GAClT,mDACA","debugId":null}},
    {"offset": {"line": 664, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"","debugId":null}}]
}